#!/usr/bin/env python3
"""
Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø¹Ù…ÙˆÙ…ÛŒ Ø§Ø² NeuroSymGen Ø¨Ø±Ø§ÛŒ Ù‡Ø± task
Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø¯Ù‡Ø§ÛŒ task-specific (XSS, Phishing, ...) Ø±Ùˆ Ø§Ø¶Ø§ÙÙ‡ Ù…ÛŒâ€ŒÚ©Ù†ÛŒÙ…
"""

from neurosymgen import NeuroSymGenLayer, GrokReActAgent, HardwareOptimizer
from neurosymgen.kg.hetero_graph import create_sample_hetero_kg
import torch
import pandas as pd
from sklearn.model_selection import train_test_split


# ============================================================
# âœ… Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø¯Ù‡Ø§ÛŒ task-specific Ø±Ùˆ Ù…ÛŒâ€ŒÙ†ÙˆÛŒØ³ÛŒÙ…
# ============================================================

def create_xss_kg(num_features: int = 128, num_nodes: int = 5):
    """
    XSS-specific KG - Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ø§Ø´Ù‡ Ù†Ù‡ ØªÙˆ core library
    """
    nodes = []
    patterns = {
        "script_tag": "script",
        "event_handler": "onerror",
        "javascript_proto": "javascript:",
        "svg_payload": "svg",
        "iframe_inject": "iframe"
    }

    for pattern in patterns.values():
        feature = torch.randn(num_features)
        # Ø§Ú¯Ù‡ pattern ØªÙˆÛŒ payload Ø¨Ø§Ø´Ù‡ØŒ Ø§ÙˆÙ„ÛŒÙ† 10 dim Ø±Ùˆ 1 Ú©Ù†
        nodes.append(feature)

    while len(nodes) < num_nodes:
        nodes.append(torch.randn(num_features))

    return torch.stack(nodes).unsqueeze(0)  # [1, 5, 128]


def create_phishing_kg(num_features: int = 128):
    """
    Phishing-specific KG
    """
    nodes = []
    patterns = {
        "login_form": "login",
        "urgent_language": "urgent",
        "mismatched_url": "url_mismatch",
        "suspicious_sender": "sender",
        "https_check": "https"
    }

    for _ in patterns:
        nodes.append(torch.randn(num_features))

    return torch.stack(nodes).unsqueeze(0)


def create_sentiment_kg(num_features: int = 128):
    """
    Sentiment-specific KG
    """
    nodes = []
    patterns = {
        "positive_words": ["good", "great", "excellent"],
        "negative_words": ["bad", "terrible", "awful"],
        "intensifiers": ["very", "extremely", "absolutely"],
        "negations": ["not", "never", "no"],
        "emojis": ["ğŸ˜Š", "ğŸ˜¢", "ğŸ˜¡"]
    }

    for _ in patterns:
        nodes.append(torch.randn(num_features))

    return torch.stack(nodes).unsqueeze(0)


# ============================================================
# âœ… CORE: General Dataset
# ============================================================

class GeneralDataset(torch.utils.data.Dataset):
    def __init__(self, csv_path, text_column, label_column, max_len=512, task="generic"):
        self.df = pd.read_csv(csv_path)
        self.max_len = max_len
        self.task = task
        self.text_column = text_column

        self.vocab = self._build_vocab(text_column)

    def _build_vocab(self, text_column):
        chars = set()
        for text in self.df[text_column]:
            chars.update(str(text))
        return {c: i + 1 for i, c in enumerate(sorted(chars))}

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        text = str(self.df.iloc[idx][self.text_column])
        label = int(self.df.iloc[idx][label_column])

        # Encode
        encoded = [self.vocab.get(c, 0) for c in text[:self.max_len]]
        encoded += [0] * (self.max_len - len(encoded))
        x = torch.tensor(encoded, dtype=torch.float32)

        # KG: Ø¨Ø± Ø§Ø³Ø§Ø³ task Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†
        if self.task == "xss":
            kg_data = create_xss_kg()
        elif self.task == "phishing":
            kg_data = create_phishing_kg()
        elif self.task == "sentiment":
            kg_data = create_sentiment_kg()
        else:
            kg_data = create_sample_hetero_kg().concept.x.unsqueeze(0)

        return x, kg_data, torch.tensor(label, dtype=torch.float32)


# ============================================================
# âœ… MAIN
# ============================================================

def main():
    import sys
    task = sys.argv[1] if len(sys.argv) > 1 else "xss"

    dataset = GeneralDataset(
        csv_path=f"{task}_dataset.csv",
        text_column="text",  # ÛŒØ§ payload ÛŒØ§ email
        label_column="label",
        task=task
    )

    model = NeuroSymGenLayer(input_size=512, num_rules=4, output_size=1)
    train_and_eval(model, dataset, task=task)


if __name__ == "__main__":
    main()