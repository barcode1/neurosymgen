"""
ISCAI 2025 Hardware Benchmark Script for NeuroSymGen.
Run this on A100/H100 to generate performance numbers.
**Ø±ÙˆÛŒ CPU Ù‡Ù… Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ù‡ (Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ MSVC)**
"""

import torch
import sys
import os
import json

# Add parent directory to path for local testing
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from neurosymgen import NeuroSymGenLayer, HardwareProfiler, HardwareOptimizer


def run_benchmark_suite():
    """Run complete hardware benchmark suite"""
    print("ğŸš€ ISCAI 2025 NeuroSymGen Hardware Benchmark")
    print("==================================================")

    device = "cuda" if torch.cuda.is_available() else "cpu"
    if device == "cpu":
        print("âš ï¸  Warning: CUDA not detected. Running on CPU.")
        print("    Set TORCH_COMPILE_DISABLE=1 to avoid compile errors\n")

    # Test configurations (Ú©ÙˆÚ†Ú©ØªØ± Ø¨Ø±Ø§ÛŒ CPU)
    # configs = [
    #     {"batch": 2, "input": 128, "rules": 4, "output": 64},
    #     {"batch": 4, "input": 256, "rules": 8, "output": 128},
    # ]
    #
    # if device == "cpu":
    #     configs = [{"batch": 4, "input": 128, "rules": 8, "output": 64}]
    configs = [
        {"batch": 16, "input": 512, "rules": 16, "output": 256},  # Real-world size
        {"batch": 32, "input": 1024, "rules": 32, "output": 512},  # Large model
        {"batch": 64, "input": 2048, "rules": 64, "output": 1024},  # ISCAI scale
    ]

    if device == "cpu":
        configs = [{"batch": 8, "input": 256, "rules": 16, "output": 128}]

    results = []

    for i, cfg in enumerate(configs):
        print(f"\nğŸ“Š Test {i + 1}/{len(configs)}: {cfg}")

        try:
            # Initialize model
            model = NeuroSymGenLayer(
                input_size=cfg["input"],
                num_rules=cfg["rules"],
                output_size=cfg["output"]
            ).to(device)

            # Optimize (Ø±ÙˆÛŒ CPU Ø®ÙˆØ¯Ú©Ø§Ø± safe mode ÙØ¹Ø§Ù„ Ù…ÛŒâ€ŒØ´Ù‡)
            optimizer = HardwareOptimizer(model, device=device)

            # Create sample inputs
            x = torch.randn(cfg["batch"], cfg["input"]).to(device)
            kg_data = torch.randn(cfg["batch"], 5, cfg["output"]).to(device)

            # Profile (Ø¨Ø¯ÙˆÙ† torch.compile Ø±ÙˆÛŒ CPU)
            profiler = HardwareProfiler(model, device=device)
            metrics = profiler.profile_full_forward(x, kg_data=kg_data)

            # Optimize with benchmark
            sample_input = x
            optimized_model = optimizer.optimize(sample_input)

            # Benchmark the optimized version
            bench_metrics = optimizer.benchmark({"x": x, "kg_data": kg_data})

            # Combine results
            metrics.update(cfg)
            metrics.update(bench_metrics)
            metrics["optimization_gain"] = (
                    (metrics["latency_ms"] - bench_metrics["latency_ms"]) / metrics["latency_ms"] * 100
            )

            results.append(metrics)

            print(f"  âœ… Latency: {metrics['latency_ms']:.2f} ms")
            print(f"  âœ… Optimized: {bench_metrics['latency_ms']:.2f} ms")
            print(f"  âœ… Gain: {metrics['optimization_gain']:.1f}%")

        except Exception as e:
            print(f"  âŒ Error in config {cfg}: {e}")
            print("     Skipping to next config...")
            continue

    # Save results
    if results:
        with open("iscai_results.json", "w") as f:
            json.dump(results, f, indent=2)
        print("\nâœ… Benchmark complete! Results saved to iscsi_results.json")

        # Summary
        avg_gain = sum(r.get("optimization_gain", 0) for r in results) / len(results)
        print(f"\nğŸ“ˆ Average optimization gain: {avg_gain:.1f}%")
    else:
        print("\nâŒ No successful benchmarks completed")


if __name__ == "__main__":
    # ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ù…Ø­ÛŒØ·ÛŒ Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² compile Ø±ÙˆÛŒ CPU
    if not torch.cuda.is_available():
        os.environ["TORCH_COMPILE_DISABLE"] = "1"
        print("ğŸ”§ TORCH_COMPILE_DISABLE=1 set for CPU execution")

    run_benchmark_suite()